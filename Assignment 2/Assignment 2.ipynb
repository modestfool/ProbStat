{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Problem Solving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 (b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dice_toss = ss.binom(100,1.0/6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lower_bound,upper_bound = dice_toss.ppf(0.025),dice_toss.ppf(0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(c) . Given the following number of rolls until the dice become biased, can you conclude that it is 95% probable that aluminum performs better? (hint: may assume rolls until biased is well approximated as a Normal).\n",
    "aluminum rolls until biased = [136, 73, 118, 122, 114, 103, 149, 118, 113, 105]\n",
    "plastic rolls until biased = [129, 89, 97, 94, 124, 77, 85, 86, 86, 69]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aluminium_rolls = [136, 73, 118, 122, 114, 103, 149, 118, 113, 105]\n",
    "plastic_rolls = [129, 89, 97, 94, 124, 77, 85, 86, 86, 69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean1, mean2 = np.mean(aluminium_rolls), np.mean(plastic_rolls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print mean1, mean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1, s2 = np.std(aluminium_rolls), np.std(plastic_rolls)\n",
    "print s1, s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n1 = n2 = 10\n",
    "df1,df2 = n1-1,n2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = (float)(mean1-mean2)/np.sqrt((s1**2/n1) + (s2**2)/n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 1 - ss.t.cdf(np.abs(t), df1+df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss.ttest_ind(aluminium_rolls,plastic_rolls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "from numpy import matrix\n",
    "\n",
    "X = matrix ([[-1,2,1],[4,12,1],[3,5,1],[4,6,1],[-3,9,1],[6,7,1]])\n",
    "\n",
    "R = ((X.T) * X).I * (X.T)\n",
    "\n",
    "Y = matrix ([[2.5],[10],[8.5],[4],[1.5],[14]])\n",
    "out = R* Y\n",
    "\n",
    "print out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from __future__ import division\n",
    "beta_0 = 0.0\n",
    "beta_p = 0.0\n",
    "left_handed = [0, 0, 1, 0, 0, 1]\n",
    "plus_minus = [-1,4,3,4,-3,6]\n",
    "\n",
    "diag = [0]*6\n",
    "z = [0]*6\n",
    "I = ([1]*6)\n",
    "X = np.matrix([I, plus_minus]).T\n",
    "#print X\n",
    "while(1):\n",
    "    prev_beta_0 = beta_0\n",
    "    prev_beta_p = beta_p\n",
    "    for i in range(6):\n",
    "        q = math.exp(beta_0 + plus_minus[i]*beta_p)\n",
    "        p = q/(1+q)\n",
    "        diag[i] = p*(1-p)\n",
    "        z[i] = math.log(p/(1-p)) + ((left_handed[i] - p)/(p*(1-p)))\n",
    "    W = np.matrix(np.diag(diag))\n",
    "    #print W\n",
    "    Z = np.matrix(z).T\n",
    "    #print Z\n",
    "    beta = (((X.T)*W*X).I)*(X.T)*W*(Z)\n",
    "    beta_p = beta.item(1)\n",
    "    beta_0 = beta.item(0)\n",
    "    #print beta\n",
    "    if (round(beta_p,2) - round(prev_beta_p,2) < 0.01):\n",
    "        break\n",
    "print beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.matrix ([[-1, 1],[4,1],[3,1],[4,1],[-3,1],[6,1]])\n",
    "X_t = X.T\n",
    "W = np.matrix(np.diag([0.25, 0.25, 0.25,0.25,0.25,0.25]))\n",
    "z = np.matrix([[-2],[-2],[2],[-2],[-2],[2]])\n",
    "r = X_t*W\n",
    "r = (r*X).I\n",
    "q = r*X_t\n",
    "s = q*W\n",
    "result = s*z\n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part II: Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read and tokenize the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import scipy.stats as ss\n",
    "from happierfuntokenizing import Tokenizer\n",
    "from BeautifulSoup import BeautifulSoup as Soup\n",
    "from __future__ import division\n",
    "import traceback\n",
    "import json\n",
    "import re\n",
    "import operator\n",
    "import math\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import threading\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#from threading import Thread\n",
    "#from multiprocessing import Pool\n",
    "#import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_blogs(path,filename,users,global_words_dict,industry_map,topics):\n",
    "    tokenizer = Tokenizer()\n",
    "    regex = r'<post>[\\s\\S]*?</post>'\n",
    "    total_blog_posts = 0\n",
    "    \n",
    "    parts = filename.split(\".\")\n",
    "    #print parts\n",
    "    features_dict = {}\n",
    "    words_dict ={}\n",
    "    user_total_words = 0\n",
    "\n",
    "    user_id = (int)(parts[0])\n",
    "    gender = parts[1]\n",
    "    age = (int)(parts[2])\n",
    "    industry = parts[3]\n",
    "    star_sign = parts[4]\n",
    "\n",
    "    if user_id in users:\n",
    "        features_dict = users[user_id]\n",
    "\n",
    "    if industry in industry_map:\n",
    "        tmp_count = industry_map[industry]\n",
    "        tmp_count = tmp_count + 1\n",
    "        industry_map[industry] = tmp_count\n",
    "    else:\n",
    "        industry_map[industry] = 1\n",
    "            \n",
    "    with open(path + filename, 'r') as user_blog:\n",
    "        user_blogs = user_blog.read().replace('\\n', '').replace('\\r', '').replace('\\t', '')\n",
    "    \n",
    "    blog_posts = re.findall(regex, user_blogs, re.DOTALL)\n",
    "\n",
    "    total_blog_posts = total_blog_posts + len(blog_posts)\n",
    "    user_total_words = 0\n",
    "    #for blog in soup.findAll('post'):\n",
    "    for blog in blog_posts:  \n",
    "        words = tokenizer.tokenize(blog.strip())\n",
    "        user_total_words += len(words)\n",
    "\n",
    "        if 'dict' in features_dict:\n",
    "            words_dict = features_dict['dict']\n",
    "\n",
    "        for word in words:\n",
    "            if word in words_dict:\n",
    "                count = words_dict[word]\n",
    "                count = count + 1\n",
    "                words_dict[word] = count\n",
    "            else:\n",
    "                words_dict[word] = 1\n",
    "\n",
    "            if word in global_words_dict:\n",
    "                count = global_words_dict[word]\n",
    "                count = count + 1\n",
    "                global_words_dict[word] = count\n",
    "            else:\n",
    "                global_words_dict[word] = 1\n",
    "\n",
    "    topics_prob = {}\n",
    "\n",
    "    for i in range(2000):\n",
    "        prob = 0.0\n",
    "        topic_dict = topics[topics['category'] == i]\n",
    "\n",
    "        for row in topic_dict.itertuples():\n",
    "            word = row[1]\n",
    "            prob_topic_given_word = row[3]\n",
    "            if word in words_dict:\n",
    "                count_user_word = words_dict[word]\n",
    "                prob_word_given_user = count_user_word/user_total_words\n",
    "\n",
    "                cur = prob_topic_given_word * prob_word_given_user\n",
    "\n",
    "                prob = prob + cur\n",
    "        topics_prob[i] = prob\n",
    "\n",
    "    features_dict['dict'] = words_dict\n",
    "    features_dict['age'] = age\n",
    "    features_dict['industry'] = industry\n",
    "    features_dict['star_sign'] = star_sign\n",
    "    features_dict['user_id'] = user_id\n",
    "    features_dict['topics'] = topics_prob\n",
    "    features_dict['total_count'] = user_total_words\n",
    "    features_dict['gender'] = gender\n",
    "    users[user_id] = features_dict\n",
    "    #print user_id , \"completed\"\n",
    "    #return total_blog_posts\n",
    "    return (users, global_words_dict, industry_map, total_blog_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_blogs(path):\n",
    "    users = {}\n",
    "    global_words_dict = {}\n",
    "    industry_map = {}\n",
    "    total_users = 0\n",
    "    total_blog_posts = 0\n",
    "    iterations = 0\n",
    "    topics = pd.read_csv('wwbpFBtopics_condProb.csv')\n",
    "    pool = ThreadPool(processes=1)\n",
    "    jobs = []\n",
    "    for filename in os.listdir(path):\n",
    "        iterations += 1\n",
    "        if iterations > 500:\n",
    "            break\n",
    "        if iterations % 10 == 0:\n",
    "            print \"user %d\" %iterations\n",
    "        \n",
    "        #t = Thread(target= process_blogs, args=(path,filename,users,industry_map,global_words_dict,topics,))\n",
    "        #t.start()\n",
    "        #t = multiprocessing.Process(target= process_blogs, args=(path,filename,users,industry_map,global_words_dict,topics,)) \n",
    "        #jobs.append(t)\n",
    "        #t.start()\n",
    "        #total_blog_posts += t.join()\n",
    "    #for j in jobs:\n",
    "        #j.join()\n",
    "    return (users, global_words_dict, industry_map, total_blog_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users, all_dict, industry_map, num_blogs  = parse_blogs('blogs/')\n",
    "print \"1. a) posts: \" ,num_blogs\n",
    "print \"1. b) users: \" , len(users)\n",
    "print \"1. c) words: \" , len(all_dict)\n",
    "print \"1. d) \", industry_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "print datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Calculate users’ probability of mentioning each topic (“topic usage”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = pd.read_csv('wwbpFBtopics_condProb.csv')\n",
    "topic_map = {}\n",
    "\n",
    "topic_map[463] = topics[topics[\"category\"]==463]\n",
    "topic_map[963] = topics[topics[\"category\"]==963]\n",
    "topic_map[981] = topics[topics[\"category\"]==981]\n",
    "\n",
    "user_ids = sorted(k for k in users)\n",
    "lowest_user_ids = sorted(user_ids)[0:3]\n",
    "\n",
    "print \"2.a)\"\n",
    "for userid in lowest_user_ids:\n",
    "    print \"%d\" %userid\n",
    "    \n",
    "    word_counts_map = users[userid]['dict']\n",
    "\n",
    "    all_words_wc = 0\n",
    "    \n",
    "    for w,c in word_counts_map.iteritems():\n",
    "        all_words_wc = all_words_wc + word_counts_map[w]\n",
    "        \n",
    "    #print word_counts_map\n",
    "    \n",
    "    for topic in topic_map:\n",
    "        print topic,\" : \"\n",
    "        \n",
    "        prob = 0\n",
    "        topic_pd = topic_map[topic]\n",
    "        \n",
    "        #print topic_pd\n",
    "        for index, row in topic_pd.iterrows():\n",
    "            word = row[0]\n",
    "            prob_topic_given_word = row[2]\n",
    "\n",
    "            if word in word_counts_map:\n",
    "                count_user_word = word_counts_map[word]\n",
    "                prob_word_given_user = count_user_word / all_words_wc\n",
    "\n",
    "                #print prob_topic_given_word , prob_word_given_user\n",
    "                cur = prob_topic_given_word * prob_word_given_user\n",
    "\n",
    "                prob = prob + cur\n",
    "            \n",
    "        print prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Correlate each topic usage with user age, adjusting for gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta_topics = {}\n",
    "beta_gender = {}\n",
    "beta_significant = {}\n",
    "beta_p_value = {}\n",
    "\n",
    "topics_user ={}\n",
    "\n",
    "alpha = 0.05/2000\n",
    "\n",
    "for topic in range(2000):\n",
    "    topics = []\n",
    "    gender = []\n",
    "    Y_rows = []\n",
    "    for user,features in users.iteritems():\n",
    "        \n",
    "        if topic in topics_user:\n",
    "            user_topic = topics_user[topic]\n",
    "        else:\n",
    "            user_topic = {}\n",
    "        \n",
    "        user_topic[user] = features['topics'][topic]\n",
    "        \n",
    "        topics_user[topic] = user_topic\n",
    "        \n",
    "        topics.append(features['topics'][topic])\n",
    "        gender.append(1 if features['gender'] == 'male' else 0)\n",
    "        Y_rows.append([features['age']])\n",
    "    try:\n",
    "       \n",
    "        topics = (topics - np.mean(topics))/np.std(topics)\n",
    "        gender = (gender - np.mean(gender))/np.std(gender)\n",
    "        Y_rows = (Y_rows - np.mean(Y_rows))/np.std(Y_rows)\n",
    "        \n",
    "        \n",
    "        #break\n",
    "        #X = np.matrix([topics,gender]).T\n",
    "        X = []\n",
    "        for i in range(len(topics)):\n",
    "            X.append([topics[i],gender[i]])\n",
    "        Y = []\n",
    "        for i in range(len(topics)):\n",
    "            Y.append([Y_rows[i]])\n",
    "        X = np.matrix(X)\n",
    "        Y = np.matrix(Y_rows)\n",
    "        Y = (Y - np.mean(Y))/np.std(Y)\n",
    "        '''print X.shape\n",
    "        print Y.shape'''\n",
    "        #break\n",
    "        beta = (((X.T)*X).I)*(X.T)*Y\n",
    "        #print beta\n",
    "        beta_topics[topic] = beta.item(0)\n",
    "        beta_gender[topic] = beta.item(1)\n",
    "    except Exception as e:\n",
    "        #print e, topic, user\n",
    "        continue\n",
    "    RSS = 0\n",
    "    SE_topic = 0\n",
    "    SE_gender = 0\n",
    "    mean_topic = np.mean(topics)\n",
    "    mean_gender = np.mean(gender)\n",
    "\n",
    "    for i in range(len(users)):\n",
    "        y_i = Y_rows[i][0]\n",
    "        x_topic_i = topics[i]\n",
    "        x_gender_i = gender[i]\n",
    "        beta_topic_ = beta.item(0)\n",
    "        beta_gender_ = beta.item(1)\n",
    "        x_i = (beta_topic_*x_topic_i) + (beta_gender_*x_gender_i)\n",
    "        \n",
    "        RSS = RSS + ((y_i- x_i)**2)\n",
    "        SE_topic =  SE_topic + ((x_topic_i - mean_topic)**2)\n",
    "        #print y_i, x_i, RSS, SE_topic\n",
    "    \n",
    "    n = len(users)\n",
    "    k = 2\n",
    "    s_square = RSS/(n-k-1)\n",
    "    t_topic = beta_topic_/(math.sqrt(s_square/SE_topic))\n",
    "    p_value = ss.t.sf(np.abs(t_topic),len(users)-2)*2\n",
    "    beta_p_value[topic] = p_value\n",
    "    beta_significant[topic] = 'Yes' if p_value < alpha else 'No'\n",
    "\n",
    "top_positive_topics = sorted(beta_topics.items(), key=operator.itemgetter(1),reverse = True)[:10]\n",
    "top_negative_topics = sorted(beta_topics.items(), key=operator.itemgetter(1))[:10]\n",
    "print '3.a)'\n",
    "for topic, corr in top_positive_topics:\n",
    "    print 'topic_id: %d, correlation: %0.3f, p-value: %f, signficant after correction? %s' \\\n",
    "    %(topic,corr,beta_p_value[topic], beta_significant[topic])\n",
    "print '3. b)' \n",
    "for topic, corr in top_negative_topics:\n",
    "    print 'topic_id: %d, correlation: %0.3f, p-value: %f, signficant after correction? %s' \\\n",
    "    %(topic,corr,beta_p_value[topic],beta_significant[topic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Correlate each topic usage with user industry, adjusting for gender and age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "industry_topic_beta = {}\n",
    "for industry in industry_map:\n",
    "    #if industry_map[industry] < 30:\n",
    "        #continue\n",
    "    topics_list = {}\n",
    "    for topic in range(2000):\n",
    "        beta_0 = 0.0\n",
    "        beta_topic= 0.0\n",
    "        beta_age = 0.0\n",
    "        beta_gender = 0.0\n",
    "        topics = []\n",
    "        industry_row = []\n",
    "        gender = []\n",
    "        age = []\n",
    "        constant = [1]*len(users)\n",
    "        for user,features in users.iteritems():\n",
    "            if 'topics' in features:\n",
    "                topics.append(features['topics'][topic])\n",
    "            else:\n",
    "                topics.append(0)\n",
    "            gender.append(1 if features['gender'] == 'male' else 0)\n",
    "            age.append(features['age'])\n",
    "            industry_row.append(0 if features['industry'] == industry else 1)\n",
    "        \n",
    "        age = (age - np.mean(age))/np.std(age)\n",
    "        gender = (gender - np.mean(gender))/np.std(gender)\n",
    "        topics = (topics - np.mean(topics))/np.std(topics)\n",
    "        \n",
    "        X = []\n",
    "        for i in range(len(users)):\n",
    "            X.append([topics[i],gender[i],age[i]])\n",
    "        X = np.matrix(X)\n",
    "       \n",
    "        #X = np.matrix([topics,gender,age,constant]).T\n",
    "        Y = np.matrix(industry_row).T\n",
    "         \n",
    "        try:\n",
    "            while(1):\n",
    "                prev_beta_0 = beta_0\n",
    "                prev_beta_topic = beta_topic\n",
    "                prev_beta_age = beta_age\n",
    "                prev_beta_gender = beta_gender\n",
    "                beta_matrix = np.matrix([beta_topic,beta_gender,beta_age,beta_0])\n",
    "                diag = [0]*len(users)\n",
    "                z = [0]*len(users)\n",
    "            \n",
    "                for i in range(len(users)):\n",
    "                    q = math.exp(topics[i]*beta_topic + gender[i]*beta_gender + age[i]*beta_age)\n",
    "                    p = q/(1+q)\n",
    "                    diag[i] = p*(1-p)\n",
    "                    z[i] = math.log(p/(1-p)) + ((industry_row[i] - p)/(p*(1-p)))\n",
    "                    \n",
    "                W = np.matrix(np.diag(diag))\n",
    "                #print W\n",
    "                Z = np.matrix(z).T\n",
    "                #print Z\n",
    "                beta = (((X.T)*W*X).I)*(X.T)*W*(Z)\n",
    "\n",
    "                beta_topic = beta.item(0)\n",
    "                beta_gender = beta.item(1)\n",
    "                beta_age = beta.item(2)\n",
    "                #print beta\n",
    "                if (round(beta_topic,2) - round(prev_beta_topic,2) < 0.01):\n",
    "                    break\n",
    "        except Exception as e:\n",
    "                print e\n",
    "                break\n",
    "                continue\n",
    "        topics_list[topic] = beta_topic\n",
    "    #print topics_list\n",
    "    industry_topic_beta [industry] = topics_list\n",
    "\n",
    "#print industry_topic_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_topics = []\n",
    "print '4 a).'\n",
    "for industry,topics_list in industry_topic_beta.iteritems():\n",
    "    for topic,beta_topic in sorted(topics_list.items(), key=operator.itemgetter(1),reverse = True)[:5]:\n",
    "        if topic not in filtered_topics:\n",
    "            filtered_topics.append(topic)\n",
    "        print 'industry: %s, topic_id: %d, coefficient: %f' %(industry,topic, beta_topic)\n",
    "print '4 b).'\n",
    "for industry,topics_list in industry_topic_beta.iteritems():\n",
    "    for topic,beta_topic in sorted(topics_list.items(), key=operator.itemgetter(1))[:5]:\n",
    "        if topic not in filtered_topics:\n",
    "            filtered_topics.append(topic)\n",
    "        print 'industry: %s, topic_id: %d, coefficient: %f' %(industry,topic, beta_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5 Plot topics by Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "topics_terms_pd = pd.read_csv(\"2000topics.top20freqs.keys.csv\")\n",
    "\n",
    "Topic_ages_mean = {}\n",
    "\n",
    "colors =  matplotlib.colors.cnames.keys()[:len(users)]\n",
    "\n",
    "for topic in filtered_topics:\n",
    "\n",
    "    topic_users = topics_user[topic]\n",
    "    \n",
    "    top_topic_users = sorted(topic_users.items(),key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "    ages = []\n",
    "    num_top_users = int (round(0.25*len(topic_users)))\n",
    "\n",
    "    for user,beta in top_topic_users[:num_top_users]:\n",
    "        #print user\n",
    "        ages.append(users[user]['age'])\n",
    "\n",
    "    #print ages\n",
    "    ages_mean = np.mean(ages)\n",
    "    Topic_ages_mean[topic] = round(ages_mean,3)\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "sub_plot = 0\n",
    "for industry,topics_list in industry_topic_beta.iteritems():\n",
    "\n",
    "    top5pairs = sorted(topics_list.items(), key=operator.itemgetter(1),reverse = True)[:5]\n",
    "    bottom5pairs = sorted(topics_list.items(), key=operator.itemgetter(1))[:5]\n",
    "\n",
    "    top5pairs.extend(bottom5pairs)\n",
    "    #print top5pairs\n",
    "    X = []\n",
    "    Y = []\n",
    "    topic_terms_map = {}\n",
    "    for tid in top5pairs:\n",
    "        \n",
    "        words_list = []\n",
    "        topic = tid[0]\n",
    "        \n",
    "        X.append(round(tid[1],3))\n",
    "        Y.append(Topic_ages_mean[topic])\n",
    "        \n",
    "        topic_terms = topics_terms_pd.iloc[topic-1]\n",
    "    \n",
    "        #print topic_terms.values\n",
    "        for wd in topic_terms.values:\n",
    "            if isinstance(wd, str):\n",
    "                if len(words_list) > 3:\n",
    "                    break\n",
    "                else:\n",
    "                    words_list.append(wd)\n",
    "                \n",
    "        topic_terms_map[topic] = words_list\n",
    "    \n",
    "    tpc_words_list = topic_terms_map.values()\n",
    "    \n",
    "    fig.suptitle(industry, fontsize=14, fontweight='bold')\n",
    "    sub_plot += 1 \n",
    "    ax = fig.add_subplot(len(industry_topic_beta),1,sub_plot)\n",
    "    fig.subplots_adjust(top=20)\n",
    "    ax.set_title('Topic Correlation with %s Vs Mean Age of top 25 percent users' % (industry))\n",
    "\n",
    "    ax.set_xlabel('Topic Correlation with %s '% (industry))\n",
    "    ax.set_ylabel('Mean Age of top 25% users')\n",
    "    \n",
    "    for i in range(10):\n",
    "        #for j in range(len(tpc_words_list[i])):\n",
    "        ax.text(X[i], Y[i],'\\n'.join([','.join(tpc_words_list[i][0:2]),','.join(tpc_words_list[i][2:])]),\\\n",
    "                 fontsize=12, color = colors[i])\n",
    "        \n",
    "    ax.axis([np.min(X),np.max(X)*1.5, np.min(Y), np.max(Y)])\n",
    "#fig.tight_layout()\n",
    "plt.savefig(\"out.png\", transparent = True)\n",
    "plt.show()\n",
    "#plt.savefig(\"a1_4_histpop.png\")\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_value = ss.t.sf(np.abs(3.16),6-2)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
