{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import os\n",
    "import re\n",
    "import traceback\n",
    "from happierfuntokenizing import Tokenizer\n",
    "from __future__ import division\n",
    "\n",
    "total_number_of_blog_posts = 0\n",
    "total_number_of_users = 0\n",
    "industry_users_map = {}\n",
    "userid_industry_map = {}\n",
    "userid_age_map = {}\n",
    "userid_gender_map = {}\n",
    "\n",
    "all_words_counts = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Method for reading all files, parsing the blogs and tokenizing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_all_blogs(users_words_counts,users_topics_probs):\n",
    "    \n",
    "    global total_number_of_blog_posts\n",
    "    global total_number_of_users\n",
    "    global industry_users_map \n",
    "    global userid_industry_map\n",
    "    global userid_age_map\n",
    "    global userid_gender_map\n",
    "        \n",
    "    #global users_topics_probs\n",
    "    \n",
    "    global all_words_counts\n",
    "\n",
    "    path = \"blogs/\"\n",
    "    tokenizer_instance = Tokenizer()\n",
    "    \n",
    "    pattern = r'<post>(.*?)</post>'\n",
    "    \n",
    "    iterations = 0\n",
    "    try:\n",
    "        \n",
    "        topic_words_file = pd.read_csv(\"wwbpFBtopics_condProb.csv\")\n",
    "        \n",
    "        for filename in os.listdir(path):  #### For EACH USER\n",
    "            \n",
    "            iterations = iterations+1\n",
    "            print iterations\n",
    "            \n",
    "            if iterations>500:\n",
    "                break\n",
    "                \n",
    "            word_count_map = {}\n",
    "            topic_prob_map = {}\n",
    "            \n",
    "            if filename.startswith(\".\"):\n",
    "                continue\n",
    "                \n",
    "            all_posts = []\n",
    "            parts = filename.split(\".\")\n",
    "            \n",
    "            user_id = (int)(parts[0])\n",
    "            gender = parts[1]\n",
    "            age = (int)(parts[2])\n",
    "            industry = parts[3]\n",
    "            \n",
    "            user_total_words_count = 0\n",
    "            userid_age_map[user_id] = age\n",
    "            \n",
    "            if gender == \"male\":\n",
    "                userid_gender_map[user_id] = 0\n",
    "            else:\n",
    "                userid_gender_map[user_id] = 1\n",
    "                \n",
    "            userid_industry_map[user_id] = industry\n",
    "\n",
    "            \n",
    "            if industry in industry_users_map:\n",
    "                industry_users_map[industry] = industry_users_map[industry] + 1\n",
    "            else:\n",
    "                industry_users_map[industry] = 1\n",
    "                \n",
    "            \n",
    "            full_filename = path+filename\n",
    "            \n",
    "            with open(full_filename, 'r') as myfile:\n",
    "                text = myfile.read().replace('\\n', '').replace('\\r', '').replace('\\t', '')\n",
    "    \n",
    "            all_posts = re.findall(pattern, text, re.DOTALL)\n",
    "        \n",
    "            total_number_of_blog_posts = total_number_of_blog_posts + len(all_posts)\n",
    "            \n",
    "            ### All the posts in this user's blog\n",
    "            for blog_post in all_posts:\n",
    "                words = tokenizer_instance.tokenize(blog_post)\n",
    "\n",
    "                ### Total Number of Words This User uses\n",
    "                user_total_words_count = user_total_words_count + len(words)\n",
    "                \n",
    "                for word in words:\n",
    "                    if word in word_count_map:\n",
    "                        word_count_map[word] = word_count_map[word] + 1\n",
    "                    else:\n",
    "                        word_count_map[word] = 1   \n",
    "            \n",
    "                    if word in all_words_counts:\n",
    "                        all_words_counts[word] = all_words_counts[word] + 1\n",
    "                    else:\n",
    "                        all_words_counts[word] = 1      \n",
    "                    \n",
    "            #for word, user_wc in word_count_map.iteritems():\n",
    "            for topic in range(2000):\n",
    "                \n",
    "                ### Initializing Prob of topic given user = 0\n",
    "                prob_topic_given_user = 0.0\n",
    "\n",
    "                word_row = topic_words_file[topic_words_file[\"category\"]==topic]\n",
    "                \n",
    "                for index, row in word_row.iterrows():\n",
    "                    word = row[0]\n",
    "                    prob_topic_given_word = row[2]\n",
    "                    \n",
    "                    if word in word_count_map:\n",
    "                        user_wc = word_count_map[word]\n",
    "                        \n",
    "                        prob_word_given_user = user_wc / user_total_words_count\n",
    "\n",
    "                        cur = prob_topic_given_word * prob_word_given_user\n",
    "                        prob_topic_given_user = prob_topic_given_user + cur\n",
    "                    \n",
    "                topic_prob_map[topic] = prob_topic_given_user\n",
    "                        \n",
    "                \n",
    "            users_words_counts[user_id] = word_count_map\n",
    "            users_topics_probs[user_id] = topic_prob_map\n",
    "                \n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    print \"1.a) posts: %d \" % total_number_of_blog_posts\n",
    "    print \"1.b) users: %d \" % len(userid_age_map)\n",
    "    print \"1.c) words: %d \" % len(all_words_counts)\n",
    "    print \"1.d) \"\n",
    "    print industry_users_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print userid_age_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-82b1261ceff9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0musers_topics_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mread_all_blogs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers_words_counts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0musers_topics_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-3b1e18bf264a>\u001b[0m in \u001b[0;36mread_all_blogs\u001b[0;34m(users_words_counts, users_topics_probs)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mword_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_words_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic_words_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"category\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_row\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0mprob_topic_given_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/basavakanaparthi/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/basavakanaparthi/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 data = _sanitize_array(data, index, dtype, copy,\n\u001b[0;32m--> 225\u001b[0;31m                                        raise_cast_failure=True)\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/basavakanaparthi/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_sanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m   2811\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2812\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2813\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/basavakanaparthi/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_try_cast\u001b[0;34m(arr, take_fast_path)\u001b[0m\n\u001b[1;32m   2779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2780\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2781\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_possibly_cast_to_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2782\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_internal_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2783\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/basavakanaparthi/anaconda/lib/python2.7/site-packages/pandas/core/common.pyc\u001b[0m in \u001b[0;36m_possibly_cast_to_datetime\u001b[0;34m(value, dtype, errors)\u001b[0m\n\u001b[1;32m   1634\u001b[0m         elif not (is_array and not (issubclass(value.dtype.type, np.integer) or\n\u001b[1;32m   1635\u001b[0m                                     value.dtype == np.object_)):\n\u001b[0;32m-> 1636\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_possibly_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/basavakanaparthi/anaconda/lib/python2.7/site-packages/pandas/core/common.pyc\u001b[0m in \u001b[0;36m_possibly_infer_to_datetimelike\u001b[0;34m(value, convert_dates)\u001b[0m\n\u001b[1;32m   1707\u001b[0m         \u001b[0;31m# do a quick inference for perf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1709\u001b[0;31m         \u001b[0minferred_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'datetime'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'datetime64'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconvert_dates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    users_words_counts = {}\n",
    "    users_topics_probs = {}\n",
    "\n",
    "    read_all_blogs(users_words_counts,users_topics_probs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2) Calculating first 3 users' probability of mentioning 3 given topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topicwordsfile = pd.read_csv(\"wwbpFBtopics_condProb.csv\")\n",
    "\n",
    "topic_map = {}\n",
    "\n",
    "topic_map[463] = topicwordsfile[topicwordsfile[\"category\"]==463]\n",
    "topic_map[963] = topicwordsfile[topicwordsfile[\"category\"]==963]\n",
    "topic_map[981] = topicwordsfile[topicwordsfile[\"category\"]==981]\n",
    "\n",
    "#print topic_map[963]\n",
    "\n",
    "lowest_user_ids = [5114,7596,8173]\n",
    "\n",
    "print \"2.a)\"\n",
    "for userid in lowest_user_ids:\n",
    "    print \"%d\" %userid\n",
    "    \n",
    "    for topic in topic_map:\n",
    "        print str(topic) + \" : \"\n",
    "        \n",
    "        prob_topic_given_user = users_topics_probs[topic]\n",
    "        print prob_topic_given_user\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3) Correlate each topic usage with user age, adjusting for gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multiply_matrices(Topics, Genders, Ages):\n",
    "    Ones = []\n",
    "    for i in range(len(Topics)):\n",
    "        Ones.append(1)\n",
    "        \n",
    "    Right = np.matrix([Topics,Genders,Ones])\n",
    "    Right = Right.T\n",
    "    \n",
    "    Left = np.matrix([Ages])\n",
    "    Left = Left.T\n",
    "    \n",
    "    print Right\n",
    "    \n",
    "    Right_T = Right.T\n",
    "    \n",
    "    XT_X = Right_T * Right\n",
    "    XT_X_I = XT_X.I\n",
    "    \n",
    "    XT_X_I_XT = XT_X_I * Right_T\n",
    "    \n",
    "    Betas = XT_X_I_XT * Left\n",
    "    \n",
    "    return Betas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306244\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "[[  2.99160083e-05   1.00000000e+00   1.00000000e+00]\n",
      " [  2.51238251e-05   0.00000000e+00   1.00000000e+00]\n",
      " [  5.48985766e-05   0.00000000e+00   1.00000000e+00]\n",
      " ..., \n",
      " [  1.14318328e-05   0.00000000e+00   1.00000000e+00]\n",
      " [  1.54081162e-05   0.00000000e+00   1.00000000e+00]\n",
      " [  2.91616897e-05   1.00000000e+00   1.00000000e+00]]\n",
      "[-846.926092720302]\n"
     ]
    }
   ],
   "source": [
    "# T is topic usage , A is User's Age , G is User's Gender\n",
    "topic_words_file = pd.read_csv(\"wwbpFBtopics_condProb.csv\")\n",
    "print len(topic_words_file)\n",
    "\n",
    "Ages = userid_age_map.values()\n",
    "Genders = userid_gender_map.values()\n",
    "\n",
    "Beta_topics = []\n",
    "Beta_C = []\n",
    "\n",
    "for topic in range(2000):\n",
    "    print topic\n",
    "\n",
    "    Topics = []\n",
    "    topic_pd = topic_words_file[topic_words_file[\"category\"]==topic]\n",
    "    \n",
    "    iterc =0\n",
    "    for user_id,age in userid_age_map.iteritems():\n",
    "\n",
    "        iterc = iterc + 1\n",
    "        if iterc%1000 == 0:\n",
    "            print iterc\n",
    "            \n",
    "        gender = userid_gender_map[user_id]\n",
    "        user_word_counts_map = users_words_counts[user_id]\n",
    "\n",
    "        user_all_words_count = 0\n",
    "        for w ,c in user_word_counts_map.iteritems():\n",
    "            user_all_words_count = user_all_words_count + c\n",
    "    \n",
    "        prob_topic_given_user = 0\n",
    "        \n",
    "        for index, row in topic_pd.iterrows():\n",
    "            word = row[0]\n",
    "            prob_topic_given_word = row[2]\n",
    "\n",
    "            if word in user_word_counts_map:\n",
    "                user_wc = user_word_counts_map[word]\n",
    "\n",
    "                prob_word_given_user = user_wc / user_all_words_count\n",
    "\n",
    "                cur = prob_topic_given_word * prob_word_given_user\n",
    "                prob_topic_given_user = prob_topic_given_user + cur\n",
    "\n",
    "        \n",
    "        Topics.append(prob_topic_given_user)\n",
    "    \n",
    "    Betas = multiply_matrices(Topics,Genders,Ages)\n",
    "    \n",
    "    Beta_topic = Betas.item(0)\n",
    "    Beta_c = Betas.item(2)\n",
    "    \n",
    "    Beta_C.append(Beta_c)\n",
    "    Beta_topics.append(Beta_topic)\n",
    "    \n",
    "    print Beta_topics\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as ss\n",
    "print ss.binom(100,0.1667).ppf(0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.481259759221\n"
     ]
    }
   ],
   "source": [
    "normal = ss.norm(0,1)\n",
    "print ss.t.sf(0.05, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28131261433417232"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as ss\n",
    "ss.t.sf(2.57,0.257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1293748975108234"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((19.175**2 + 18.11**2))/(19.175**2/10 + 18.11**2/10)**2)*0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10648037.704476822"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.t.isf(0.95,0.129)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "alum  = np.array([136, 73, 118, 122, 114, 103, 149, 118, 113, 105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.21248239193901"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sqrt(alum.var()*10/9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.13138237134\n",
      "[[-3.16666667]\n",
      " [ 1.83333333]\n",
      " [ 0.83333333]\n",
      " [ 1.83333333]\n",
      " [-5.16666667]\n",
      " [ 3.83333333]]\n",
      "3.13138237134\n",
      "6.83333333333\n"
     ]
    }
   ],
   "source": [
    "X = [[-1,2],[ 4 ,12],[ 3,  5],[ 4  ,6],[-3,  9],[ 6  ,7]]\n",
    "X = np.matrix(X)\n",
    "std1 = np.std(X[:,0])\n",
    "print std1\n",
    "print (X[:,0] - np.mean(X[:,0]))\n",
    "std2 = np.std(X[:,1])\n",
    "print std2\n",
    "print np.mean(X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[:,1] = (X[:,1] - np.mean(X[:,1]))/np.std(X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[:,0] = (X[:,0] - np.mean(X[:,0]))/np.std(X[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-1, -1],\n",
       "        [ 0,  1],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [-1,  0],\n",
       "        [ 1,  0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
