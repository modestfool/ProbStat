{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Problem Solving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 (b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dice_toss = ss.binom(100,1.0/6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lower_bound,upper_bound = dice_toss.ppf(0.025),dice_toss.ppf(0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(c) . Given the following number of rolls until the dice become biased, can you conclude that it is 95% probable that aluminum performs better? (hint: may assume rolls until biased is well approximated as a Normal).\n",
    "aluminum rolls until biased = [136, 73, 118, 122, 114, 103, 149, 118, 113, 105]\n",
    "plastic rolls until biased = [129, 89, 97, 94, 124, 77, 85, 86, 86, 69]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aluminium_rolls = [136, 73, 118, 122, 114, 103, 149, 118, 113, 105]\n",
    "plastic_rolls = [129, 89, 97, 94, 124, 77, 85, 86, 86, 69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean1, mean2 = np.mean(aluminium_rolls), np.mean(plastic_rolls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print mean1, mean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1, s2 = np.std(aluminium_rolls), np.std(plastic_rolls)\n",
    "print s1, s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n1 = n2 = 10\n",
    "df1,df2 = n1-1,n2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = (float)(mean1-mean2)/np.sqrt((s1**2/n1) + (s2**2)/n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 1 - ss.t.cdf(np.abs(t), df1+df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss.ttest_ind(aluminium_rolls,plastic_rolls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "from numpy import matrix\n",
    "\n",
    "X = matrix ([[-1,2,1],[4,12,1],[3,5,1],[4,6,1],[-3,9,1],[6,7,1]])\n",
    "\n",
    "R = ((X.T) * X).I * (X.T)\n",
    "\n",
    "Y = matrix ([[2.5],[10],[8.5],[4],[1.5],[14]])\n",
    "out = R* Y\n",
    "\n",
    "print out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31728045]\n",
      " [-1.35410765]]\n",
      "[[ 0.49363718]\n",
      " [-2.1113501 ]]\n",
      "[[ 0.61174703]\n",
      " [-2.62163003]]\n",
      "[[ 0.65277718]\n",
      " [-2.79836351]]\n",
      "[[ 0.65630645]\n",
      " [-2.81348557]]\n",
      "[[ 0.65632912]\n",
      " [-2.81358239]]\n",
      "[[ 0.65632912]\n",
      " [-2.81358239]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from __future__ import division\n",
    "beta_0 = 0.0\n",
    "beta_p = 0.0\n",
    "left_handed = [0, 0, 1, 0, 0, 1]\n",
    "plus_minus = [-1,4,3,4,-3,6]\n",
    "diag = [0,0,0,0,0,0]\n",
    "z = [0,0,0,0,0,0]\n",
    "I = ([1,1,1,1,1,1])\n",
    "X = np.matrix([plus_minus, I]).T\n",
    "#print X\n",
    "while(1):\n",
    "    prev_beta_0 = beta_0\n",
    "    prev_beta_p = beta_p\n",
    "    for i in range(6):\n",
    "        q = math.exp(beta_0 + plus_minus[i]*beta_p)\n",
    "        p = q/(1+q)\n",
    "        diag[i] = p*(1-p)\n",
    "        z[i] = math.log(p/(1-p)) + ((left_handed[i] - p)/(p*(1-p)))\n",
    "    W = np.matrix(np.diag(diag))\n",
    "    #print W\n",
    "    Z = np.matrix(z).T\n",
    "    #print Z\n",
    "    beta = (((X.T)*W*X).I)*(X.T)*W*(Z)\n",
    "    beta_p = beta.item(0)\n",
    "    beta_0 = beta.item(1)\n",
    "    print beta\n",
    "    if (round(beta_p,2) - round(prev_beta_p,2) < 0.01):\n",
    "        print round(beta_p,2)\n",
    "        break\n",
    "print beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31728045]\n",
      " [-1.35410765]]\n"
     ]
    }
   ],
   "source": [
    "X = np.matrix ([[-1, 1],[4,1],[3,1],[4,1],[-3,1],[6,1]])\n",
    "X_t = X.T\n",
    "W = np.matrix(np.diag([0.25, 0.25, 0.25,0.25,0.25,0.25]))\n",
    "z = np.matrix([[-2],[-2],[2],[-2],[-2],[2]])\n",
    "r = X_t*W\n",
    "r = (r*X).I\n",
    "q = r*X_t\n",
    "s = q*W\n",
    "result = s*z\n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part II: Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read and tokenize the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import scipy.stats as ss\n",
    "from happierfuntokenizing import Tokenizer\n",
    "from BeautifulSoup import BeautifulSoup as Soup\n",
    "import traceback\n",
    "import json\n",
    "users = {}\n",
    "global_words_dict = {}\n",
    "industry_map = {}\n",
    "total_users = 0\n",
    "total_blog_posts = 0\n",
    "#global_words_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_blogs(path):\n",
    "    tokenizer = Tokenizer()\n",
    "    users = {}\n",
    "    global_words_dict = {}\n",
    "    industry_map = {}\n",
    "    total_users = 0\n",
    "    total_blog_posts = 0\n",
    "    iterations = 0\n",
    "    \n",
    "    for filename in os.listdir(path):\n",
    "        iterations += 1\n",
    "        #if iterations > 10:\n",
    "         #   break\n",
    "        parts = filename.split(\".\")\n",
    "        #print parts\n",
    "        features_dict = {}\n",
    "        words_dict ={}\n",
    "        \n",
    "        user_id = (int)(parts[0])\n",
    "        \n",
    "        gender = parts[1]\n",
    "        age = (int)(parts[2])\n",
    "        industry = parts[3]\n",
    "        star_sign = parts[4]\n",
    "        \n",
    "        if user_id in users:\n",
    "            features_dict = users[user_id]\n",
    "        \n",
    "        if industry in industry_map:\n",
    "            tmp_count = industry_map[industry]\n",
    "            tmp_count = tmp_count + 1\n",
    "            industry_map[industry] = tmp_count\n",
    "        else:\n",
    "            industry_map[industry] = 1\n",
    "                \n",
    "        \n",
    "        with open(path + filename, 'r') as user_blog:\n",
    "            user_blog = user_blog.read().replace('\\n', '').replace('\\r', '').replace('\\t', '')\n",
    "            soup = Soup(user_blog)\n",
    "            total_blog_posts = total_blog_posts + len(soup.findAll('post'))\n",
    "            \n",
    "            '''for blog in soup.findAll('post'):\n",
    "                \n",
    "                words = tokenizer.tokenize(blog.getText().strip())\n",
    "                if 'dict' in features_dict:\n",
    "                    words_dict = features_dict['dict']\n",
    "                \n",
    "                for word in words:\n",
    "                    if word in words_dict:\n",
    "                        count = words_dict[word]\n",
    "                        count = count + 1\n",
    "                        words_dict[word] = count\n",
    "                    else:\n",
    "                        words_dict[word] = 1\n",
    "                \n",
    "                for word in words:\n",
    "                    if word in global_words_dict:\n",
    "                        count = global_words_dict[word]\n",
    "                        count = count + 1\n",
    "                        global_words_dict[word] = count\n",
    "                    else:\n",
    "                        global_words_dict[word] = 1'''\n",
    "        '''features_dict['dict'] = words_dict\n",
    "        features_dict['age'] = age\n",
    "        features_dict['industry'] = industry\n",
    "        features_dict['star_sign'] = star_sign\n",
    "        features_dict['user_id'] = user_id\n",
    "        users[user_id] = features_dict\n",
    "    return (users, global_words_dict, industry_map, total_blog_posts)'''\n",
    "    print 'total blog posts : %d' % total_blog_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total blog posts : 682206\n"
     ]
    }
   ],
   "source": [
    "parse_blogs('blogs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users, all_dict, industry_map, num_blogs  = parse_blogs('blogs/')\n",
    "print \"1. a) posts: \" ,num_blogs\n",
    "print \"1. b) users: \" , len(users)\n",
    "print \"1. c) words: \" , len(all_dict)\n",
    "print \"1. d) \", industry_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Calculate users’ probability of mentioning each topic (“topic usage”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics = pd.readcsv('wwbpFBtopics_condProb.csv')\n",
    "topic_map = {}\n",
    "\n",
    "topic_map[463] = topicwordsfile[topicwordsfile[\"category\"]==463]\n",
    "topic_map[963] = topicwordsfile[topicwordsfile[\"category\"]==963]\n",
    "topic_map[981] = topicwordsfile[topicwordsfile[\"category\"]==981]\n",
    "\n",
    "#print topic_map[963]\n",
    "\n",
    "lowest_user_ids = [5114,7596,8173]\n",
    "for userid in lowest_user_ids:\n",
    "    print \"%d\" %userid\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
